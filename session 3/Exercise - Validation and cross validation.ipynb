{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mglearn\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import scipy as scipy\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise\n",
    "\n",
    "In this notebook you should train a machine learning model and do hyperparameter tuning using at least 2 of the three validation methodologies we have considered. You can see how they can each be implemented in the \"Validation and cross validation\"-notebook. \n",
    "\n",
    "Below the Boston data set (which we also considered in lecture 1) is loaded. However, feel free to replace this by any other dataset of your choice (for example the Titanic dataset, the movie reviews dataset, or your own dataset if you have one!).\n",
    "\n",
    "Try to include more than one hyperparameter in the GridSearchCV. You are also welcome to replace the algorithm - you could e.g. try a decision tree (import sklearn.tree.DecisionTreeClassifier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
      "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
      "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
      "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
      "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
      "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
      "\n",
      "   LSTAT  MEDV  CAT.MEDV  \n",
      "0   4.98  24.0         0  \n",
      "1   9.14  21.6         0  \n",
      "2   4.03  34.7         1  \n",
      "3   2.94  33.4         1  \n",
      "4   5.33  36.2         1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your Excel file\n",
    "file_path = \"Boston Housing.xlsx\"\n",
    "\n",
    "# Read the Excel file into a pandas DataFrame\n",
    "boston = pd.read_excel(file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify\n",
    "print(boston.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X = boston.drop(['MEDV', 'CAT.MEDV'], axis=1, inplace=False)\n",
    "y = boston['CAT.MEDV'].copy()\n",
    "\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, random_state=69)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: change the state it will optimize the solution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of neighbors found: 1\n",
      "Best score on validation set: 1.0\n",
      "Score on training/validation set: 1.0\n",
      "Score on test set: 0.937007874015748\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "best_score = 0\n",
    "best_metrics = 'euclodean'\n",
    "for num_neighbors in range(1,15):\n",
    "    for distance_metrics in ('euclodean', 'manhattan'):\n",
    "    # Learn the model with a certain numnber of neighbors\n",
    "        knn = KNeighborsClassifier(n_neighbors=num_neighbors)\n",
    "    knn.fit(X_trainval, y_trainval)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    score = knn.score(X_trainval, y_trainval)\n",
    "    \n",
    "    # If improvement, store score and parameter\n",
    "    if score>best_score:\n",
    "        best_score = score\n",
    "        best_num_neighbors = num_neighbors\n",
    "\n",
    "# Build a model on the combine training and valiation data\n",
    "knn = KNeighborsClassifier(n_neighbors=best_num_neighbors)\n",
    "knn.fit(X_trainval, y_trainval)\n",
    "\n",
    "print(\"Best number of neighbors found: {}\".format(best_num_neighbors))\n",
    "print(\"Best score on validation set: {}\".format(best_score))\n",
    "print(\"Score on training/validation set: {}\".format(knn.score(X_trainval, y_trainval)))\n",
    "print(\"Score on test set: {}\".format(knn.score(X_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
